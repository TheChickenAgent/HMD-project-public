{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fbfcbbe-7b3a-4389-bf3f-07a97c98d17b",
   "metadata": {
    "id": "2fbfcbbe-7b3a-4389-bf3f-07a97c98d17b"
   },
   "source": [
    "# Setup LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZNNdUDmMBdt2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-31T10:21:00.504548Z",
     "iopub.status.busy": "2025-01-31T10:21:00.504229Z",
     "iopub.status.idle": "2025-01-31T10:21:00.509146Z",
     "shell.execute_reply": "2025-01-31T10:21:00.508317Z",
     "shell.execute_reply.started": "2025-01-31T10:21:00.504522Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1732100390238,
     "user": {
      "displayName": "Simone Alghisi",
      "userId": "03730826461482842686"
     },
     "user_tz": -60
    },
    "id": "ZNNdUDmMBdt2",
    "outputId": "619ac5b7-2588-41c5-eb04-84a9473c0c0d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# set the models folder, HuggingFace will look into this folder and download the model if needed\n",
    "%env HF_HOME=/kaggle/working\n",
    "#Kaggle Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae2ba22-bd98-4463-a846-dbd19d1a0495",
   "metadata": {
    "id": "1ae2ba22-bd98-4463-a846-dbd19d1a0495"
   },
   "source": [
    "```Llama-3-8B-Instruct``` is a fine-tuned versions of the base model. We need to specific prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ff04792-e2fc-4c9a-8f92-766193c5ae9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T10:21:00.510655Z",
     "iopub.status.busy": "2025-01-31T10:21:00.510351Z",
     "iopub.status.idle": "2025-01-31T10:21:00.528159Z",
     "shell.execute_reply": "2025-01-31T10:21:00.527519Z",
     "shell.execute_reply.started": "2025-01-31T10:21:00.510622Z"
    },
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1732100404646,
     "user": {
      "displayName": "Simone Alghisi",
      "userId": "03730826461482842686"
     },
     "user_tz": -60
    },
    "id": "2ff04792-e2fc-4c9a-8f92-766193c5ae9b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Adapted to only download one model as we do not have enough space for both on Kaggle\n",
    "MODELS = {\n",
    "    \"llama3\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "}\n",
    "\n",
    "TEMPLATES = {\n",
    "    \"llama3\": \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n{}<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n{}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MYGvO5a4417e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T10:21:00.529917Z",
     "iopub.status.busy": "2025-01-31T10:21:00.529616Z",
     "iopub.status.idle": "2025-01-31T10:21:00.545394Z",
     "shell.execute_reply": "2025-01-31T10:21:00.544415Z",
     "shell.execute_reply.started": "2025-01-31T10:21:00.529896Z"
    },
    "id": "MYGvO5a4417e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the HF_TOKEN\n",
    "hf_token = os.getenv('HF_TOKEN')\n",
    "print(f'HuggingFace Token: {hf_token}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_67aC_J34_Qs",
   "metadata": {
    "id": "_67aC_J34_Qs"
   },
   "source": [
    "## Download the models (Only The first time)\n",
    "\n",
    "1. Requested access [LLaMA 3](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct).\n",
    "2. Download model with code below\n",
    "3. It needs aboutire 15GB of storage space and 6-8 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "REV7w88O578u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 99,
     "referenced_widgets": [
      "93003d4a25da4177b871bfbe66c23e9a",
      "83ad52b5eae44264a64109a9c4e72122",
      "ddc112f8799a42c8bfd8f72e712435c0",
      "ef6f1daeebd24a1c82715a5aff77e967",
      "88d8d77ed5fa4a49a719716ee584de59",
      "298529c9a4214f26ab2bd9935dd89630",
      "b6afe76da067454bac56d2b5b4a93729",
      "d0bb3f0aca524832bf613ef3f1275ade",
      "53ed7b2ba46f43bfa9ab0fde19fc819f",
      "be373cf06ffa440b8c2988fd5d4800d7",
      "d2b18283577248749538e8ff16f65e54",
      "d5d74bf13b5b4305beec14186a320349",
      "882dda8de0e04421bf8c41efe0ff50d3",
      "8cbb0d9aa9f5415ea71fa5007eb55838",
      "cbe05d191acd4370854a45df64b1065c",
      "1f6e0617d70f409bb21908d52d6a0c1a",
      "91694bf4beac43ec8b51cab985541bc5",
      "ce98c9fd13094cf7b755e1fba226a667",
      "b5683cf5136b49ec982b634d4a0a2bb9",
      "496f37f6e85a489ea428fed02a491898",
      "04b24eeb1e4c46d1aa73e08dc1a57515",
      "cd1048c02e2e49cc88bd49f8bfe3347e"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-01-31T10:21:00.546895Z",
     "iopub.status.busy": "2025-01-31T10:21:00.546641Z",
     "iopub.status.idle": "2025-01-31T10:21:00.561760Z",
     "shell.execute_reply": "2025-01-31T10:21:00.560960Z",
     "shell.execute_reply.started": "2025-01-31T10:21:00.546863Z"
    },
    "executionInfo": {
     "elapsed": 678994,
     "status": "ok",
     "timestamp": 1732099853413,
     "user": {
      "displayName": "Simone Alghisi",
      "userId": "03730826461482842686"
     },
     "user_tz": -60
    },
    "id": "REV7w88O578u",
    "outputId": "be9b75ca-9129-43e4-b3f7-7b45025f0391",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "FIRST_TIME = False\n",
    "\n",
    "if FIRST_TIME:\n",
    "    from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "    import torch\n",
    "    \n",
    "    def download_models(models):\n",
    "        for model_name in models.values():\n",
    "            # triggers download of the models\n",
    "            AutoModelForCausalLM.from_pretrained(\n",
    "                model_name,\n",
    "                device_map=\"auto\",\n",
    "                torch_dtype=torch.float16\n",
    "            )\n",
    "            AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    download_models(MODELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eRG_mtQy7qH8",
   "metadata": {
    "id": "eRG_mtQy7qH8"
   },
   "source": [
    "## Setup for prompting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3364287e-938c-4b06-9ff8-3de282d400be",
   "metadata": {
    "id": "3364287e-938c-4b06-9ff8-3de282d400be"
   },
   "source": [
    "Import the required libraries and classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aa0a617-fe82-480d-978a-7dad80c620b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T10:21:00.563020Z",
     "iopub.status.busy": "2025-01-31T10:21:00.562772Z",
     "iopub.status.idle": "2025-01-31T10:21:20.857512Z",
     "shell.execute_reply": "2025-01-31T10:21:20.856619Z",
     "shell.execute_reply.started": "2025-01-31T10:21:00.563001Z"
    },
    "executionInfo": {
     "elapsed": 15580,
     "status": "ok",
     "timestamp": 1732100458968,
     "user": {
      "displayName": "Simone Alghisi",
      "userId": "03730826461482842686"
     },
     "user_tz": -60
    },
    "id": "4aa0a617-fe82-480d-978a-7dad80c620b4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "\n",
    "from typing import Tuple\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BatchEncoding, PreTrainedTokenizer, PreTrainedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6d8215-8964-4723-ad56-81603d5091fd",
   "metadata": {
    "id": "8f6d8215-8964-4723-ad56-81603d5091fd"
   },
   "source": [
    "Functions for loading the models and generate responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc3f507a-a643-4c5f-b049-225846e146be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T10:21:20.858989Z",
     "iopub.status.busy": "2025-01-31T10:21:20.858449Z",
     "iopub.status.idle": "2025-01-31T10:21:20.863743Z",
     "shell.execute_reply": "2025-01-31T10:21:20.863096Z",
     "shell.execute_reply.started": "2025-01-31T10:21:20.858963Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1732100458968,
     "user": {
      "displayName": "Simone Alghisi",
      "userId": "03730826461482842686"
     },
     "user_tz": -60
    },
    "id": "dc3f507a-a643-4c5f-b049-225846e146be",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_model(model_name: str, dtype) -> Tuple[PreTrainedModel, PreTrainedTokenizer]:\n",
    "    torch_dtype = torch.float32\n",
    "    if dtype == \"bf16\":\n",
    "        torch_dtype = torch.bfloat16\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch_dtype,\n",
    "\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return model, tokenizer\n",
    "\n",
    "def generate(\n",
    "    model: PreTrainedModel,\n",
    "    inputs: BatchEncoding,\n",
    "    tokenizer: PreTrainedTokenizer,\n",
    "    max_seq_length: int,\n",
    ") -> str:\n",
    "    output = model.generate(\n",
    "        inputs.input_ids,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        max_length=max_seq_length,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    return tokenizer.decode(\n",
    "        output[0][len(inputs.input_ids[0]) :], skip_special_tokens=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f84fca-854a-411d-b00f-4f105e039687",
   "metadata": {
    "id": "d8f84fca-854a-411d-b00f-4f105e039687"
   },
   "source": [
    "Parameters and input for the generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f467dec-07e5-409f-bff1-5a5dcfa2b0ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T10:21:20.865806Z",
     "iopub.status.busy": "2025-01-31T10:21:20.865612Z",
     "iopub.status.idle": "2025-01-31T10:21:20.962749Z",
     "shell.execute_reply": "2025-01-31T10:21:20.962087Z",
     "shell.execute_reply.started": "2025-01-31T10:21:20.865788Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1732100458969,
     "user": {
      "displayName": "Simone Alghisi",
      "userId": "03730826461482842686"
     },
     "user_tz": -60
    },
    "id": "8f467dec-07e5-409f-bff1-5a5dcfa2b0ed",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_name = \"llama3\"\n",
    "chat_template = TEMPLATES[model_name]\n",
    "model_name = MODELS[model_name]\n",
    "\n",
    "dtype = \"bf16\"\n",
    "#max_seq_length = 1024\n",
    "max_seq_length = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892d3a6f-64d3-46d9-a56f-554c24d76695",
   "metadata": {
    "id": "892d3a6f-64d3-46d9-a56f-554c24d76695"
   },
   "source": [
    "Load the model and tokenizer based on the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb702d-26e1-4d3d-a475-746efbc58914",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176,
     "referenced_widgets": [
      "c3404f762598443da0f147f33cae755d",
      "5dae29c158f240e3b68695d2e326ab92",
      "06b9831997f944de96c5e76ca4c3da81",
      "2b7b981ff9054794943b066cb36ac951",
      "ad07bc379abc4bf2a733b0008c5356e0",
      "b3c5d334d9544af9a96f71c2d37882f6",
      "032751c18c5947a28533b5c5a5576d80",
      "65d5e8fd7e9a45f483bbd55204b1ef0f",
      "9a8faff6650f40bc891fcd1a2360532c",
      "3567f0f289d045b1a8c525035975b6ff",
      "598287ed5e4b430097ce2d11bb6eb721"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-01-31T10:21:20.964563Z",
     "iopub.status.busy": "2025-01-31T10:21:20.964276Z",
     "iopub.status.idle": "2025-01-31T10:22:01.736325Z",
     "shell.execute_reply": "2025-01-31T10:22:01.735647Z",
     "shell.execute_reply.started": "2025-01-31T10:21:20.964541Z"
    },
    "executionInfo": {
     "elapsed": 372807,
     "status": "ok",
     "timestamp": 1732100837873,
     "user": {
      "displayName": "Simone Alghisi",
      "userId": "03730826461482842686"
     },
     "user_tz": -60
    },
    "id": "91bb702d-26e1-4d3d-a475-746efbc58914",
    "outputId": "fa0a2ef5-d9be-40c2-a7e7-2592b0534db8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model, tokenizer = load_model(model_name, dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6134d12-20b2-4191-82e6-41068a3b85f6",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bcaa3c",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "445f6af1-3e1b-45d1-987e-edb8cd344fa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T10:22:01.737496Z",
     "iopub.status.busy": "2025-01-31T10:22:01.737174Z",
     "iopub.status.idle": "2025-01-31T10:22:01.741118Z",
     "shell.execute_reply": "2025-01-31T10:22:01.740227Z",
     "shell.execute_reply.started": "2025-01-31T10:22:01.737465Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEGMENTATION_PROMPT=\"\"\"\n",
    "Break the user input into multiple sentences based on the following intents:\n",
    "- chicken_ordering, if the user wants to order chicken.\n",
    "- drink_ordering, if the user wants to order a drink.\n",
    "- dessert_ordering, if the user wants to order a dessert.\n",
    "- appetizer_ordering, if the user wants to order an appetizer.\n",
    "- table_reservation, if the user wants to reserve a table.\n",
    "- request_information, if the user wants to know about something.\n",
    "- out_of_domain, if nothing of the above fits.\n",
    "Only provide the sentences, without the intent in list separated by commas, as follows:\n",
    "[\"sentence1\", \"sentence2\", ...]\n",
    "Do not paraphrase and do not change the contents. Only provide the list.\n",
    "\n",
    "For example:\n",
    "INPUT: \"Hi, I would like a roasted chicken with pesto sauce and potatoes. What drinks do you have?\"\n",
    "OUTPUT: [\"Hi, I would like a roasted chicken with pesto sauce and potatoes.\", \"What drinks do you have?\"]\n",
    "\n",
    "INPUT: \"Change the chicken size from medium to large please. I do not want ice in my drink.\"\n",
    "OUTPUT: [\"Change the chicken size from medium to large please.\", \"I do not want ice in my drink.\"]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd25303",
   "metadata": {},
   "source": [
    "## NLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "789f7bca-f577-4be2-8852-fb23081e29fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T10:22:01.742018Z",
     "iopub.status.busy": "2025-01-31T10:22:01.741812Z",
     "iopub.status.idle": "2025-01-31T10:22:01.762418Z",
     "shell.execute_reply": "2025-01-31T10:22:01.761703Z",
     "shell.execute_reply.started": "2025-01-31T10:22:01.742001Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "NLU_PROMPT = \"\"\"\n",
    "You are a Natural Language Understanding component of a human dialogue system.\n",
    "Identify the user intent from this list: [chicken_ordering, drink_ordering, dessert_ordering, table_reservation, request_information, out_of_domain].\n",
    "- chicken_ordering, if the user wants to order chicken.\n",
    "- drink_ordering, if the user wants to order a drink.\n",
    "- dessert_ordering, if the user wants to order a dessert.\n",
    "- appetizer_ordering, if the user wants to order an appetizer.\n",
    "- table_reservation, if the user wants to reserve a table.\n",
    "- request_information, if the user wants to know about something.\n",
    "- out_of_domain, if nothing of the above fits.\n",
    "\n",
    "If the intent is chicken_ordering, extract the following slot values from the user input:\n",
    "- chicken_type, the type of chicken. Choose from: [\"grilled\", \"roasted\"].\n",
    "- chicken_size, the size of the chicken. Choose from: [\"small\", \"medium\", \"large\"].\n",
    "- chicken_bones, if the user wants the chicken with bones in it. Choose from: [\"yes\", \"no\"].\n",
    "- sauce_type, the type of sauce that is served with the chicken. Choose from: [\"mushroom\", \"pesto\", \"none\"].\n",
    "- side_dish, the side dish that is served with the chicken. Choose from: [\"carrots\", \"smashed potatoes\", \"none\"]. \n",
    "If no values are present in the user input you have to put \"null\" as the value. If the value is not among the candidates, then put \"null\". Output them in a JSON format. Only output the JSON file.\n",
    "The JSON format is:\n",
    "{\n",
    "    \"intent\": \"intent_value\",\n",
    "    \"slots\": {\n",
    "        \"slot1\": \"value1\",\n",
    "        \"slot2\": \"value2\",\n",
    "        \"slot3\": \"value3\",\n",
    "        \"slot4\": \"value4\",\n",
    "        \"slot5\": \"value5\"\n",
    "    }\n",
    "}\n",
    "For example:\n",
    "INPUT: \"I would like a medium chicken.\"\n",
    "{\n",
    "    'intent': 'chicken_ordering',\n",
    "    'slots':\n",
    "    {\n",
    "        'chicken_type': \"null\",\n",
    "        'chicken_size': 'medium',\n",
    "        'chicken_bones': \"null\",\n",
    "        'sauce_type': \"null\",\n",
    "        'side_dish': \"null\"\n",
    "    }\n",
    "}\n",
    "\n",
    "If the intent is drink_ordering, extract the following slot values from the user input:\n",
    "- drink_type: the type of drink. Choose from: [\"Coca Cola\", \"Fanta\", \"Sprite\", \"Water\"].\n",
    "- drink_size, the size of the drink. Choose from: [\"small\", \"medium\", \"large\"].\n",
    "- ice: if the user wants ice in the drink. Choose from: [\"yes\", \"no\"].\n",
    "If no values are present in the user input you have to put \"null\" as the value. If the value is not among the candidates, then put \"null\". Output them in a JSON format. Only output the JSON file.\n",
    "For example: \"Please add a Fanta as my drink.\"\n",
    "{\n",
    "    \"intent\": \"drink_ordering\",\n",
    "    \"slots\": {\n",
    "        \"drink_type\": \"Fanta\",\n",
    "        \"drink_size\": \"null\",\n",
    "        \"ice\": \"null\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "If the intent is dessert_ordering, extract the following slot values from the user input:\n",
    "- dessert_type, the type of dessert. Choose from: [\"tiramisu\", \"ice cream\", \"apple crumble pie\", \"waffles\", \"smoothie\"].\n",
    "- extra_whipped_cream, if the user wants extra whipped cream. Choose from: [\"yes\", \"no\"].\n",
    "If no values are present in the user input you have to put \"null\" as the value. If the value is not among the candidates, then put \"null\". Output them in a JSON format. Only output the JSON file.\n",
    "For example: \"I would like a tiramisu with whipped cream for dessert.\"\n",
    "{\n",
    "    \"intent\": \"dessert_ordering\",\n",
    "    \"slots\": {\n",
    "        \"dessert_type\": \"tiramisu\",\n",
    "        \"extra_whipped_cream\": \"yes\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "If the intent is appetizer_ordering, extract the following slot values from the user input:\n",
    "- appetizer_type, the type of appetizer. Choose from: [\"crisps\", \"simple salad\", \"deluxe salad\", \"tomato soup\", \"onion soup\"].\n",
    "- appetizer_moment, the time before the main course that the appetizer should arrive. Choose an integer based on the user input.\n",
    "If no values are present in the user input you have to put \"null\" as the value. If the value is not among the candidates, then put \"null\". Output them in a JSON format. Only output the JSON file.\n",
    "For example: \"Please bring me a deluxe salad 8 minutes before the main course.\"\n",
    "{\n",
    "    \"intent\": \"appetizer_ordering\",\n",
    "    \"slots\": {\n",
    "        \"appetizer_type\": \"deluxe salad\",\n",
    "        \"appetizer_moment\": \"8\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "If the intent is table_reservation, extract the following slot values from the user input:\n",
    "- table_type, the type of table the user wants to reserve. Choose from: [\"normal\", \"business\", \"romantic\"].\n",
    "- table_size, the number of people that should fit at the table. Choose an integer based on the user input.\n",
    "- sitting_equipment, if the user wants chairs or benches. Choose from: [\"chair(s)\", \"bench(es)\", \"mixed chairs and benches\", \"does not matter\"].\n",
    "- birthday_surprise, if the user is celebrating someone's birthday at the dinner. Choose from [\"yes\", \"no\"].\n",
    "If no values are present in the user input you have to put \"null\" as the value. If the value is not among the candidates, then put \"null\". Output them in a JSON format. Only output the JSON file.\n",
    "For example: \"I would like to reserve a table for 3 for a business meeting.\"\n",
    "{\n",
    "    \"intent\": \"table_reservation\",\n",
    "    \"slots\": {\n",
    "        \"table_type\": \"business\",\n",
    "        \"table_size\": \"3\",\n",
    "        \"sitting_equipment\": \"null\",\n",
    "        \"birthday_surprise\": \"null\"\n",
    "    }\n",
    "}\n",
    "For example: \"We would like to reserve a table of size 5 for a birthday surprise.\"\n",
    "{\n",
    "    \"intent\": \"table_reservation\",\n",
    "    \"slots\": {\n",
    "        \"table_type\": \"null\",\n",
    "        \"table_size\": \"5\",\n",
    "        \"sitting_equipment\": \"null\",\n",
    "        \"birthday_surprise\": \"yes\"\n",
    "    }\n",
    "}\n",
    "For example: \"No, we are not planning a birthday surprise.\"\n",
    "{\n",
    "    \"intent\": \"table_reservation\",\n",
    "    \"slots\": {\n",
    "        \"table_type\": \"null\",\n",
    "        \"table_size\": \"null\",\n",
    "        \"sitting_equipment\": \"null\",\n",
    "        \"birthday_surprise\": \"no\"\n",
    "    }\n",
    "}\n",
    "\n",
    "If the intent is request_information(entity):\n",
    "Output it in a JSON format.\n",
    "Only output the JSON file.\n",
    "The JSON format is:\n",
    "{\n",
    "    \"intent\": \"request_information(entity)\"\n",
    "}\n",
    "For example: \"What drinks do you have?\"\n",
    "{\n",
    "    \"intent\": \"request_information(drink_ordering)\"\n",
    "}\n",
    "For example: \"What chickens do you offer?\"\n",
    "{\n",
    "    \"intent\": \"request_information(chicken_ordering)\"\n",
    "}\n",
    "\n",
    "If the intent is out_of_domain:\n",
    "Output it in JSON format.\n",
    "Only output the JSON file.\n",
    "The JSON format is:\n",
    "{\n",
    "    \"intent\": \"out_of_domain\"\n",
    "}\n",
    "Examples of out_of_domain are:\n",
    "- \"I would like to order pizza.\"\n",
    "- \"I want to order a notebook.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78790dd",
   "metadata": {},
   "source": [
    "## DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9257e83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T10:22:01.763314Z",
     "iopub.status.busy": "2025-01-31T10:22:01.763121Z",
     "iopub.status.idle": "2025-01-31T10:22:01.780603Z",
     "shell.execute_reply": "2025-01-31T10:22:01.779923Z",
     "shell.execute_reply.started": "2025-01-31T10:22:01.763297Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DM_PROMPT = \"\"\"\n",
    "You are a Dialogue Manager of a human dialogue system.\n",
    "Given the outputs of the NLU component which is in a JSON format, you should only generate the next best actions from this list:\n",
    "- request_details(slot), if a slot value is missing (None) by substituting slot with the missing slot name. The slot value is missing when None is the value.\n",
    "- confirmation(intent), if all the values in the slots are filled. The slot is also filled when 'none' is the value.\n",
    "- fallback_policy, if intent is out_of_domain.\n",
    "- provide_information(entity), if the intent is request_information(entity).\n",
    "- error_handling, if intent is set to error_handling.\n",
    "Pay close attention that 'none' is not the same as None. 'none' is a filled field. None is an missing slot value.\n",
    "Do not generate any other text.\n",
    "\n",
    "For example:\n",
    "INPUT: {'intent': 'chicken_ordering', 'slots': {'chicken_size': 'small', 'chicken_bones': 'yes', 'sauce_type': 'mushroom', 'side_dish': 'carrots', 'chicken_type': None}}\n",
    "OUTPUT: request_details(chicken_type)\n",
    "\n",
    "INPUT: {'intent': 'drink_ordering', 'slots': {'drink_size': 'small', 'drink_ice': 'no', 'drink_type': None}}\n",
    "OUTPUT: request_details(drink_type)\n",
    "\n",
    "INPUT: {'intent': 'dessert_ordering', 'slots': {'dessert_type': None, 'extra_whipped_cream': 'yes'}}\n",
    "OUTPUT: request_details(dessert_type)\n",
    "\n",
    "INPUT: {'intent': 'appetizer_ordering', 'slots': {'appetizer_moment': '2', 'appetizer_type': None}}\n",
    "OUTPUT: request_details(appetizer_type)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0248d9a9",
   "metadata": {},
   "source": [
    "## NLG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a95b03f5-8571-4432-a508-eece5c083042",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T10:22:01.781834Z",
     "iopub.status.busy": "2025-01-31T10:22:01.781525Z",
     "iopub.status.idle": "2025-01-31T10:22:01.799672Z",
     "shell.execute_reply": "2025-01-31T10:22:01.798757Z",
     "shell.execute_reply.started": "2025-01-31T10:22:01.781797Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "NLG_PROMPT = \"\"\"\n",
    "You are the Natural Language Generation component of a human dialogue system. You must be very polite.\n",
    "Given the next best action classified by the Dialogue Manager, you should only generate a lexicalized response for the user.\n",
    "Prioritize provide_information before request_details.\n",
    "Possible next best actions are:\n",
    "- request_details(slot), generate an appropiate question to ask the users for the missing slot value.\n",
    "- confirmation(intent), generate an appropiate confirmation message for the user intent. Fill in all the slot values.\n",
    "- fallback_policy, generate an appropiate response to tell the user that the system is not designed to handle the request.\n",
    "- error_handling(value), generate an appropiate response to tell the user that this value is not available.\n",
    "- provide_information(entity), generate information about the entity, based on the options below.\n",
    "\n",
    "Only propose options for slot values that are in the list below. The slot is the word before the \":\"\n",
    "- chicken_type, [\"grilled\", \"roasted\"].\n",
    "- chicken_size, [\"small\", \"medium\", \"large\"].\n",
    "- chicken_bones, [\"yes\", \"no\"].\n",
    "- sauce_type, [\"mushroom\", \"pesto\", \"none\"].\n",
    "- side_dish, [\"carrots\", \"smashed potatoes\", \"none\"].\n",
    "- drink_type, [\"Coca Cola\", \"Fanta\", \"Sprite\", \"Water\"].\n",
    "- drink_size, [\"small\", \"medium\", \"large\"].\n",
    "- ice, [\"yes\", \"no\"].\n",
    "- dessert_type, [\"tiramisu\", \"ice cream\", \"apple crumble pie\", \"waffles\", \"smoothie\"].\n",
    "- extra_whipped_cream, [\"yes\", \"no\"].\n",
    "- appetizer_type, [\"crisps\", \"simple salad\", \"deluxe salad\", \"tomato soup\", \"onion soup\"].\n",
    "- appetizer_moment, the time before the main course that the appetizer should arrive as an integer\n",
    "- table_type, [\"normal\", \"business\", \"romantic\"].\n",
    "- table_size, the number of people that should fit at the table as an integer.\n",
    "- sitting_equipment, [\"chair(s)\", \"bench(es)\", \"mixed chairs and benches\", \"does not matter\"].\n",
    "- birthday_surprise, [\"yes\", \"no\"].\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32b64dda-5407-4651-a45a-f35ea5653875",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T10:22:01.800728Z",
     "iopub.status.busy": "2025-01-31T10:22:01.800498Z",
     "iopub.status.idle": "2025-01-31T10:22:01.816186Z",
     "shell.execute_reply": "2025-01-31T10:22:01.815561Z",
     "shell.execute_reply.started": "2025-01-31T10:22:01.800710Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "NLG_PROMPT_CONFIRM = \"\"\"\n",
    "You are the Natural Language Generation component of a human dialogue system. You must be very polite.\n",
    "Your task is to summarize the order given the NLU that you are given. You must mention all slots values from the NLU.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde24d41-a115-47f4-a0b1-07d2ba12d8bb",
   "metadata": {},
   "source": [
    "## Database manager\n",
    "This piece of code checks if all values are within specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3acd1525-d526-4f48-a198-1c84e5511968",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T10:22:01.817074Z",
     "iopub.status.busy": "2025-01-31T10:22:01.816895Z",
     "iopub.status.idle": "2025-01-31T10:22:01.833824Z",
     "shell.execute_reply": "2025-01-31T10:22:01.833210Z",
     "shell.execute_reply.started": "2025-01-31T10:22:01.817058Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Method 1: use a library:\n",
    "#!pip install word2number\n",
    "#from word2number import w2n\n",
    "#text = \"three\"\n",
    "#number = w2n.word_to_num(text)\n",
    "#print(number)  # Output: 3\n",
    "\n",
    "#Method 2: use a custom function that lies within reasonable specification\n",
    "def word_to_num(word):\n",
    "    words_to_numbers = {\n",
    "        \"one\": 1,\n",
    "        \"two\": 2,\n",
    "        \"three\": 3,\n",
    "        \"four\": 4,\n",
    "        \"five\": 5,\n",
    "        \"six\": 6,\n",
    "        \"seven\": 7,\n",
    "        \"eight\": 8,\n",
    "        \"nine\": 9,\n",
    "        \"ten\": 10,\n",
    "        \"eleven\": 11,\n",
    "        \"twelve\": 12,\n",
    "        \"thirteen\": 13,\n",
    "        \"fourteen\": 14,\n",
    "        \"fifteen\": 15,\n",
    "        \"sixteen\": 16,\n",
    "        \"seventeen\": 17,\n",
    "        \"eighteen\": 18,\n",
    "        \"nineteen\": 19,\n",
    "        \"twenty\": 20\n",
    "    }\n",
    "    return words_to_numbers.get(word.lower(), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91be30b3-4b43-43d8-9f37-c0bdc339245f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T10:22:01.834647Z",
     "iopub.status.busy": "2025-01-31T10:22:01.834399Z",
     "iopub.status.idle": "2025-01-31T10:22:01.844679Z",
     "shell.execute_reply": "2025-01-31T10:22:01.843942Z",
     "shell.execute_reply.started": "2025-01-31T10:22:01.834627Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def validate_slots(data):\n",
    "    # Define valid options for each slot\n",
    "    valid_options = {\n",
    "        'chicken_type': [\"grilled\", \"roasted\", \"null\"],\n",
    "        'chicken_size': [\"small\", \"medium\", \"large\", \"null\"],\n",
    "        'chicken_bones': [\"yes\", \"no\", \"null\"],\n",
    "        'sauce_type': [\"mushroom\", \"pesto\", \"none\", \"null\"],\n",
    "        'side_dish': [\"carrots\", \"smashed potatoes\", \"none\", \"null\"],\n",
    "        'drink_type': [\"Cola\", \"Coca Cola\", \"Fanta\", \"Sprite\", \"Water\", \"null\"],\n",
    "        'drink_size': [\"small\", \"medium\", \"large\", \"null\"],\n",
    "        'ice': [\"yes\", \"no\", \"null\"],\n",
    "        'dessert_type': [\"tiramisu\", \"ice cream\", \"apple crumble pie\", \"waffles\", \"smoothie\", \"null\"],\n",
    "        'extra_whipped_cream': [\"yes\", \"no\", \"null\"],\n",
    "        'appetizer_type': [\"crisps\", \"simple salad\", \"deluxe salad\", \"tomato soup\", \"onion soup\", \"null\"],\n",
    "        'appetizer_moment': int, # Must be an integer\n",
    "        'table_type': [\"normal\", \"business\", \"romantic\", \"null\"],\n",
    "        'table_size': int,  # Must be an integer\n",
    "        'sitting_equipment': [\"chair(s)\", \"bench(es)\", \"mixed chairs and benches\", \"does not matter\", \"null\"],\n",
    "        'birthday_surprise': [\"yes\", \"no\", \"null\"]\n",
    "    }\n",
    "\n",
    "    # Define valid intents\n",
    "    valid_base_intents = [\n",
    "        \"chicken_ordering\",\n",
    "        \"drink_ordering\",\n",
    "        \"dessert_ordering\",\n",
    "        \"table_reservation\"\n",
    "    ]\n",
    "    valid_intents = valid_base_intents + [f\"request_information({intent})\" for intent in valid_base_intents]\n",
    "    valid_intents = valid_intents + [\"out_of_domain\"]\n",
    "    \n",
    "    # Check intent\n",
    "    intent = data.get('intent')\n",
    "    if intent not in valid_intents:\n",
    "        return False, None\n",
    "\n",
    "    # If intent is a request_information intent, ensure no slots are provided\n",
    "    if intent.startswith(\"request_information(\"):\n",
    "        base_intent = intent[len(\"request_information(\"):-1]\n",
    "        if base_intent not in valid_base_intents or data.get('slots'):\n",
    "            return False, None\n",
    "        return True, None\n",
    "\n",
    "    # Check slots\n",
    "    slots = data.get('slots', {})\n",
    "    for slot, value in slots.items():\n",
    "        # Skip validation if the value is None\n",
    "        if value is None:\n",
    "            continue\n",
    "\n",
    "        # Check if slot is in valid options\n",
    "        if slot not in valid_options:\n",
    "            return False, None\n",
    "\n",
    "        # Validate value based on its type or list of valid values\n",
    "        valid_values = valid_options[slot]\n",
    "        if isinstance(valid_values, list):\n",
    "            if value not in valid_values:\n",
    "                return False, value\n",
    "        elif valid_values == int:\n",
    "            if value.isdigit(): #E.g.\"50\".isdigit() = True\n",
    "                continue\n",
    "            value = word_to_num(value)\n",
    "            if not isinstance(value, int):\n",
    "                return False, value\n",
    "\n",
    "    return True, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535fd6a8-0880-4e23-a577-71091ce90a90",
   "metadata": {},
   "source": [
    "## DST Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce69e5ad-9836-43b6-bb81-14544dec98e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T10:22:01.845730Z",
     "iopub.status.busy": "2025-01-31T10:22:01.845428Z",
     "iopub.status.idle": "2025-01-31T10:22:01.863966Z",
     "shell.execute_reply": "2025-01-31T10:22:01.863337Z",
     "shell.execute_reply.started": "2025-01-31T10:22:01.845701Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class DialogueStateTracker:\n",
    "    def __init__(self):\n",
    "        self.previous_state = {\"NLU\": None, \"DM\": None}\n",
    "        self.order_confirmed = False\n",
    "        self.not_working_value = None\n",
    "\n",
    "    def update_nlu_state(self, nlu_out: str):\n",
    "        nlu_out_dict = dict(eval(self.find_dictionary(nlu_out)))\n",
    "        nlu_out_dict = self.change_null(nlu_out_dict)\n",
    "\n",
    "        # Check the validity of the slots\n",
    "        valid_bool, value = validate_slots(nlu_out_dict)\n",
    "\n",
    "        \n",
    "        \n",
    "        if valid_bool == False:\n",
    "            print(\"Error handling active\")\n",
    "            self.update_dm_state(\"error_handling\")\n",
    "            if value is not None:\n",
    "                self.update_not_working_value(value)\n",
    "        else:\n",
    "            if self.previous_state[\"NLU\"] is None:\n",
    "                self.previous_state[\"NLU\"] = nlu_out_dict\n",
    "            else: \n",
    "                self.previous_state[\"NLU\"] = self.deepmerge_dicts(self.previous_state[\"NLU\"], nlu_out_dict)\n",
    "        return self.previous_state\n",
    "\n",
    "    def update_not_working_value(self, value):\n",
    "        self.not_working_value = value\n",
    "        \n",
    "    def get_not_working_value(self):\n",
    "        return self.not_working_value\n",
    "        \n",
    "    def error_handling(self):\n",
    "        self.previous_state[\"NLU\"] = {\"intent\": \"error_handling\"}\n",
    "        return self.previous_state\n",
    "\n",
    "    def check_slot_values_null(self):\n",
    "        if dst.get_state()[\"NLU\"] == None:\n",
    "            return True #e.g. by error-handling\n",
    "        if 'slots' not in list(dst.get_state()[\"NLU\"].keys()):\n",
    "            return True #e.g. for request_information\n",
    "        else:\n",
    "            return None in list(dst.get_state()[\"NLU\"]['slots'].values())\n",
    "\n",
    "    def update_dm_state(self, dm_out: str):\n",
    "        self.previous_state[\"DM\"] = dm_out\n",
    "        return self.previous_state\n",
    "    \n",
    "    def get_state(self):\n",
    "        return self.previous_state\n",
    "    \n",
    "    def order_confirmation(self):\n",
    "        self.order_confirmed = True\n",
    "\n",
    "    def get_confirmation_status(self):\n",
    "        return self.order_confirmed\n",
    "    \n",
    "    def change_null(self, dictionary: dict) -> dict:\n",
    "        \"\"\"\n",
    "        Recursively replaces all occurrences of the string \"null\" with Python's None in the given dictionary.\n",
    "\n",
    "        Args:\n",
    "            dictionary (dict): The input dictionary.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary with \"null\" replaced by None.\n",
    "        \"\"\"\n",
    "        for key, value in dictionary.items():\n",
    "            if value == \"null\":\n",
    "                dictionary[key] = None\n",
    "            elif isinstance(value, dict):  # If the value is a dictionary, recurse.\n",
    "                dictionary[key] = self.change_null(value)\n",
    "        return dictionary\n",
    "    \n",
    "    def deepmerge_dicts(self, d1: dict, d2: dict) -> dict:\n",
    "        merged = {}\n",
    "        for key in set(d1) | set(d2):\n",
    "            if key in d1 and key in d2:\n",
    "                if isinstance(d1[key], dict) and isinstance(d2[key], dict):\n",
    "                    merged[key] = self.deepmerge_dicts(d1[key], d2[key])\n",
    "                else:\n",
    "                    #Take latest value, in case user wants to change option.\n",
    "                    if d2[key] is None:\n",
    "                        merged[key] = d1[key]\n",
    "                    else:\n",
    "                        merged[key] = d2[key]\n",
    "            elif key in d1:\n",
    "                merged[key] = d1[key]\n",
    "            else:\n",
    "                merged[key] = d2[key]\n",
    "        return merged\n",
    "    \n",
    "    def find_dictionary(self, text: str) -> str:\n",
    "        opening_bracket = [(match.start(), match.group()) for match in re.finditer(r'[{]', text)]\n",
    "        opening_index = opening_bracket[0][0]\n",
    "\n",
    "        closing_bracket = [(match.start(), match.group()) for match in re.finditer(r'[}]', text)]\n",
    "        closing_index = closing_bracket[-1][0]\n",
    "\n",
    "        dictionary_from_llm = text[opening_index:closing_index+1]\n",
    "        return dictionary_from_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "433c6d29-cde4-4e85-9f9b-f82187abe680",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T10:32:27.729217Z",
     "iopub.status.busy": "2025-01-31T10:32:27.728938Z",
     "iopub.status.idle": "2025-01-31T10:32:27.736653Z",
     "shell.execute_reply": "2025-01-31T10:32:27.735760Z",
     "shell.execute_reply.started": "2025-01-31T10:32:27.729196Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def postprocess_nlg(nlg_output):\n",
    "    nlg_output = nlg_output.replace('\"', '')\n",
    "    nlg_output = nlg_output.replace('\\n', '')\n",
    "    if \":\" in nlg_output:\n",
    "        nlg_output = nlg_output.split(':', 1)[1].strip()\n",
    "    return nlg_output\n",
    "\n",
    "def postprocess_nlg_summary(nlg_output):\n",
    "    if \":\" in nlg_output:\n",
    "        nlg_output = nlg_output.split(':', 1)[1].strip()\n",
    "    return nlg_output\n",
    "    \n",
    "def postprocess_dm(dm_output):\n",
    "    if \"\\n\" in dm_output:\n",
    "        dm_output = dm_output.strip(\"\\n\")\n",
    "    if \"'\" in dm_output:\n",
    "        dm_output = dm_output.replace(\"'\", \"\")\n",
    "    if '\"' in dm_output:\n",
    "        dm_output = dm_output.replace('\"', '')\n",
    "    return dm_output\n",
    "\n",
    "def use_LLM(PROMPT, text):\n",
    "    input_template = chat_template.format(PROMPT, text)\n",
    "    output_tokenizer = tokenizer(input_template, return_tensors=\"pt\").to(model.device)\n",
    "    output = generate(model, output_tokenizer, tokenizer, max_seq_length)\n",
    "    return output\n",
    "\n",
    "def generate_goodybye(DSTs):\n",
    "    intents = []\n",
    "    for dst in DSTs:\n",
    "        intent = dst.get_state()[\"NLU\"][\"intent\"] #get the state\n",
    "        #check if it does not start with request_information\n",
    "        if \"request_information\" not in intent:\n",
    "            typ = intent.split(\"_\")[0] #get the thing before the underscore\n",
    "            intents.append(typ)\n",
    "    out = \"Thanks for ordering \"\n",
    "    for typ in intents:\n",
    "        if len(intents) == 1: #if there is only one order, just output the name\n",
    "            out = out + typ\n",
    "        else:\n",
    "            if typ == intents[-1]: #if we are at the last element, use an extra 'and'\n",
    "                out = out + \"and \" + typ\n",
    "            else:\n",
    "                out = out + typ + \", \"\n",
    "    out = out + \"\\nGoodbye!\"\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bd0cf0-dce7-44cf-941f-7c39bcfe15c1",
   "metadata": {},
   "source": [
    "# Full pipeline - NEW V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75f50b9c-589a-467d-aa64-00c1a18e6a42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T10:37:29.325783Z",
     "iopub.status.busy": "2025-01-31T10:37:29.325502Z",
     "iopub.status.idle": "2025-01-31T10:37:29.329088Z",
     "shell.execute_reply": "2025-01-31T10:37:29.328465Z",
     "shell.execute_reply.started": "2025-01-31T10:37:29.325763Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc567f1b-3e28-48a5-9c59-d04773528c4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T10:39:56.579057Z",
     "iopub.status.busy": "2025-01-31T10:39:56.578735Z",
     "iopub.status.idle": "2025-01-31T10:43:19.571192Z",
     "shell.execute_reply": "2025-01-31T10:43:19.570479Z",
     "shell.execute_reply.started": "2025-01-31T10:39:56.579030Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Welcome to chicken restaurant ROASTED. How can I help you today?\")\n",
    "\n",
    "STOP_FLAGS = []\n",
    "start_conv = True\n",
    "DSTs = []\n",
    "confirmed_orders_dsts = []\n",
    "\n",
    "while len(DSTs) == 0 or not all([dst.get_confirmation_status() for dst in DSTs]):\n",
    "    user_input = input()\n",
    "    outputs = []\n",
    "    \n",
    "    #SEGMENT\n",
    "    i = 0\n",
    "    while i<5: #Max 5 attemtps\n",
    "        try:\n",
    "            segment_output = use_LLM(SEGMENTATION_PROMPT, user_input)\n",
    "            # Try to decode the JSON string\n",
    "            segment_output = json.loads(segment_output)\n",
    "            segmentation_correct = True\n",
    "            break  # Exit the loop if decoding is successful\n",
    "        except json.JSONDecodeError as e:\n",
    "            i = i + 1\n",
    "            if DEBUG: print(f\"JSONDecodeError while segmenting, try again: {e}\")\n",
    "\n",
    "    if segmentation_correct == False: #if the segmentation failed for more than 5 times, we fallback\n",
    "        nlg_output = use_LLM(NLG_PROMPT, \"fallback_policy\")\n",
    "        #POSTPROCESS\n",
    "        nlg_output_postprocessed = postprocess_nlg(nlg_output)\n",
    "        if DEBUG: print(nlg_output_postprocessed)\n",
    "    else: #else, we continue with the putting the segmentation to the NLU\n",
    "        for i in range(len(segment_output)):\n",
    "            segment = segment_output[i]\n",
    "            if DEBUG: print(f\"SEGMENT: {segment}\")\n",
    "            \n",
    "            #Check if there is an empty segment, if so do nothing\n",
    "            segment = segment.replace(\"\\n\", \"\")\n",
    "            if len(segment) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                nlu_output = use_LLM(NLU_PROMPT, segment)\n",
    "                if DEBUG: print(f\"NLU_OUTPUT LLAMA: {nlu_output}\")\n",
    "    \n",
    "            #Check if DST has such a intent:\n",
    "            #if so continue there\n",
    "            #else add a new DST\n",
    "            if len(DSTs) == 0: #If there is not a single one in the list, then create one\n",
    "                dst = DialogueStateTracker()\n",
    "                DSTs.append(dst)\n",
    "                #print(\"INIT FIRST ONE\")\n",
    "            else: #Else, search through the DSTs if there is one with the same intent, take it else create new\n",
    "                #print(\"FINDING DST\")\n",
    "                found_flag = False\n",
    "                for dst in DSTs:\n",
    "                    if dst.get_state()[\"NLU\"] == None:\n",
    "                        continue\n",
    "                    a = str(dst.get_state()[\"NLU\"][\"intent\"]) in str(nlu_output)\n",
    "                    b = not dst.get_confirmation_status()\n",
    "                    #a = str(nlu_output).__contains__(str(dst.get_state()[\"NLU\"][\"intent\"]))\n",
    "                    if a and b:# and not b:# and not \"provide_information\" in str(dst.get_state()[\"DM\"]):\n",
    "                        #print(\"FOUND DST:\", DSTs.index(dst))\n",
    "                        dst = dst\n",
    "                        found_flag = True\n",
    "                        break #we found the corresponding dst\n",
    "                if found_flag == False: #there is no one in there yet, so we make one for the intent\n",
    "                    #print(\"CREATING NEW DST\")\n",
    "                    dst = DialogueStateTracker()\n",
    "                    DSTs.append(dst)\n",
    "            \n",
    "            #Try to update the NLU, assuming the correct format.\n",
    "            try:\n",
    "                dst.update_nlu_state(nlu_out=nlu_output)\n",
    "            except Exception as e:\n",
    "                if DEBUG: \n",
    "                    print(f\"An unexpected error occurred: {e} in segment {segment}.\")\n",
    "                    print(\"Activating error handling.\")\n",
    "            nlu_in_dst = str(dst.get_state()[\"NLU\"])\n",
    "            if DEBUG:\n",
    "                print(\"NLU:\")\n",
    "                print(nlu_in_dst)\n",
    "                print()\n",
    "\n",
    "        # Now, we have processed all segments to the NLU, we continue with the DSTs\n",
    "        for dst in DSTs:\n",
    "            if DEBUG:\n",
    "                print(\"NLU_state\", str(dst.get_state()[\"NLU\"]))\n",
    "                print(\"DM_state\", str(dst.get_state()[\"DM\"]))\n",
    "            if (dst.get_state()[\"NLU\"]) == None:\n",
    "                if str(dst.get_state()[\"DM\"]) == \"error_handling\":\n",
    "                    if DEBUG: print(\"DST found with error handling, setting DM_output to error_handling\")\n",
    "                    dm_output = \"error_handling\"\n",
    "                else:\n",
    "                    continue\n",
    "            elif dst.get_confirmation_status():\n",
    "                continue\n",
    "            elif dst.check_slot_values_null() == False:\n",
    "                dm_output = f\"confirmation('{dst.get_state()['NLU']['intent']}')\"\n",
    "            else:\n",
    "                dm_output = use_LLM(DM_PROMPT, str(dst.get_state()[\"NLU\"]))\n",
    "                dm_output = postprocess_dm(dm_output) #overwrite to dm_output as that's what we use\n",
    "            dst.update_dm_state(dm_out=dm_output)\n",
    "            dm_in_dst = str(dst.get_state()[\"DM\"])\n",
    "            if DEBUG: print(\"DM:\", dm_in_dst)\n",
    "\n",
    "            # If all values are filled and we are not handling an error\n",
    "            if str(dst.get_state()[\"DM\"]) != \"error_handling\" and dst.check_slot_values_null() == False:\n",
    "                #Summarize order\n",
    "                nlg_output = use_LLM(NLG_PROMPT_CONFIRM, str(dst.get_state()))\n",
    "                nlg_output_postprocessed = postprocess_nlg_summary(nlg_output)\n",
    "                print(nlg_output_postprocessed)\n",
    "\n",
    "                #User confirmation\n",
    "                response_not_recognized = True\n",
    "                while response_not_recognized:\n",
    "                    user_input = input(\"Confirmation with YES or NO:\")\n",
    "                    user_input = str(user_input).lower()\n",
    "                    if \"yes\" in user_input or \"y\" in user_input:\n",
    "                        dst.order_confirmation()\n",
    "                        confirmed_orders_dsts.append(dst)\n",
    "                        response_not_recognized = False\n",
    "                        #print('Thanks for your order.')\n",
    "                        inte = str(dst.get_state()[\"NLU\"][\"intent\"])\n",
    "                        #c_message = \"Your order has been placed\"\n",
    "                        c_message = f\"Your {inte.replace('_', ' ')} has been placed!\"\n",
    "                        outputs.append(c_message)\n",
    "                    elif \"no\" in user_input or \"n\" in user_input:\n",
    "                        response_not_recognized = False\n",
    "                        print(\"Please specify what you want to change in your next turn.\")\n",
    "                        inte = str(dst.get_state()[\"NLU\"][\"intent\"])\n",
    "                        changing_message = f\"What would you like to change in your {inte.replace('_', ' ')}?\"\n",
    "                        outputs.append(changing_message)\n",
    "                    else:\n",
    "                        print(\"Sorry, I did not understand. Do you want to confirm your order (YES) or (NO)?\")\n",
    "            elif str(dst.get_state()[\"DM\"]) == \"error_handling\":\n",
    "                val = dst.get_not_working_value()\n",
    "                if val == None:\n",
    "                    print(\"ERROR, WTF AM I DOING???\") #if this happens, check the value in nlu_update attempt with flag\n",
    "                dm_in_dst = f\"error_handling({val})\"\n",
    "                nlg_output = use_LLM(NLG_PROMPT, dm_in_dst)\n",
    "                nlg_output_postprocess = postprocess_nlg(nlg_output) #Postprocess\n",
    "                outputs.append(nlg_output_postprocess) #Append to output list\n",
    "                dm_output = None #reset dm_output\n",
    "                dst.update_dm_state(dm_out=dm_output)\n",
    "            else:\n",
    "                nlg_output = use_LLM(NLG_PROMPT, dm_in_dst)\n",
    "                nlg_output_postprocess = postprocess_nlg(nlg_output) #Postprocess\n",
    "                outputs.append(nlg_output_postprocess) #Append to output list    \n",
    "            \n",
    "            #As this is an information request and not for details, we can directly set the confirmation to True.\n",
    "            #This way we don't have to process it again next time\n",
    "            if dst.get_state()[\"NLU\"] is not None and \"request_information\" in str(dst.get_state()[\"NLU\"][\"intent\"]):\n",
    "                dst.order_confirmation()\n",
    "            #if str(dst.get_state()[\"DM\"]) == \"error_handling\":\n",
    "            #    dst.order_confirmation()\n",
    "        print()\n",
    "        if len(outputs) == 0:\n",
    "            OUT = \"\"\n",
    "        elif len(outputs) == 1:\n",
    "            OUT = outputs[0]\n",
    "        elif len(outputs) > 1:\n",
    "            OUT = \" \".join(outputs)\n",
    "        elif all([dst.get_confirmation_status() for dst in DSTs]):\n",
    "            OUT = \"Goodbye!\"\n",
    "        else:\n",
    "            print(\"Unknown problem with outputs\")\n",
    "        print(OUT)\n",
    "        print(\"=\"*50)\n",
    "print(generate_goodybye(DSTs)) #Goodbye screen with string injection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdf846c-f610-4d2c-b2c4-87237bd81c97",
   "metadata": {},
   "source": [
    "I want to drink a lemon soda.\n",
    "\n",
    "I want to drink a lemon soda.\n",
    "\n",
    "I want my drink to be of medium size without ice.\n",
    "\n",
    "Please give me a lemon soda.\n",
    "\n",
    "```I apologize, but I didn't quite catch what you said. Could you please repeat or rephrase your request? I'm here to help and want to make sure I understand correctly.```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c10c5e-6130-4b63-bc5e-d79538b42c29",
   "metadata": {},
   "source": [
    "### Examples\n",
    "#### Example 1 - mixed (chicken, drink)\n",
    "- Hi, I would like a roasted chicken with pesto sauce and smashed potatoes. What drinks do you have?\n",
    "- I would like a medium sized chicken without bones. I would like a small Coca Cola.\n",
    "- Accept chicken\n",
    "- Yes, I would like ice in my drink.\n",
    "- Accept drink\n",
    "\n",
    "#### Example 2.1 - mixed (chicken, drink, alternating)\n",
    "- Hi, I would like a roasted chicken with pesto sauce and smashed potatoes. What drinks do you have?\n",
    "- I would like a medium sized chicken without bones. I would like a small Coca Cola.\n",
    "- Reject chicken\n",
    "- Change the chicken size from medium to large please. I do not want ice in my drink. (NLU fails on 1st segment)\n",
    "- Accept drink\n",
    "- I want a large chicken instead of a medium one. (NLU works)\n",
    "- Accept chicken\n",
    "\n",
    "#### Example 2.2 - mixed (chicken, drink, alternating)\n",
    "- Hi, I would like a roasted chicken with pesto sauce and smashed potatoes. What drinks do you have?\n",
    "- I would like a medium sized chicken without bones. I would like a small Coca Cola.\n",
    "- Reject chicken\n",
    "- Change the chicken size from medium to large please. I do not want ice in my drink. (NLU works)\n",
    "- Accept both\n",
    "\n",
    "#### Example 3 - mixed later (table, chicken)\n",
    "- I would like to reserve a table for 4 persons.\n",
    "- No, we are not planning a birthday surprise.\n",
    "- I prefer a normal table. What chickens do you offer?\n",
    "- I want a mix of seats at the table.\n",
    "\n",
    "#### Example 4 - error handling (chicken, drink not from list)\n",
    "- I would like my chicken to be of medium size. For my drink, I'd like a lemon soda.\n",
    "- Please serve the chicken grilled with mushroom sauce. I want to drink a lemon soda.\n",
    "- The chicken without bones please.\n",
    "- Please serve my chicken with no side dish.\n",
    "- Accept chicken\n",
    "- I want a lemon soda. (NLU does not pick option)\n",
    "- I would really like a lemon soda please. (Nope)\n",
    "- Please, I really need a lemon soda. (Yay, error handling :) )\n",
    "\n",
    "#### Example 5 - error handling (lemon soda)\n",
    "- I want a lemon soda. (sometimes accepts)\n",
    "- I would really like a lemon soda please. (sometimes accepts)\n",
    "- Please, I really need a lemon soda.\n",
    "\n",
    "\n",
    "Keeps on asking for drink type:\n",
    "SEGMENT: I want a lemon soda.\n",
    "NLU_OUTPUT LLAMA: \n",
    "\n",
    "{\n",
    "    \"intent\": \"drink_ordering\",\n",
    "    \"slots\": {\n",
    "        \"drink_type\": \"Lemon Soda\",\n",
    "        \"drink_size\": \"null\",\n",
    "        \"ice\": \"null\"\n",
    "    }\n",
    "}\n",
    "Error handling active\n",
    "NLU:\n",
    "{'intent': 'drink_ordering', 'slots': {'drink_type': None, 'drink_size': None, 'ice': None}}\n",
    "\n",
    "DM:\n",
    "request_details('drink_type')\n",
    "\n",
    "What type of drink would you like to have with your meal? We have Coca Cola, Fanta, or Sprite available. Which one would you prefer?\n",
    "\n",
    "\n",
    "- I will settle for a Sprite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14157e1-47f1-45ce-a211-da4de3fc93d1",
   "metadata": {},
   "source": [
    "Check this sentence:\n",
    "Hi, I would like a roasted chicken with pesto sauce and broccoli.\n",
    "or\n",
    "For my drink, I'd like a lemon soda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0fbef15-e82e-4e5b-a8fc-ac5b3e7b88ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T10:26:24.616613Z",
     "iopub.status.busy": "2025-01-31T10:26:24.616326Z",
     "iopub.status.idle": "2025-01-31T10:26:24.620124Z",
     "shell.execute_reply": "2025-01-31T10:26:24.619281Z",
     "shell.execute_reply.started": "2025-01-31T10:26:24.616590Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Breaks:\n",
    "#I would like my chicken to be of medium size. For my drink, I'd like a lemon soda. becaus it picks lemon soda as drink and does not return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef72463a-dc75-4ef3-a9ba-daceabdaa709",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T10:26:24.621164Z",
     "iopub.status.busy": "2025-01-31T10:26:24.620949Z",
     "iopub.status.idle": "2025-01-31T10:26:24.636733Z",
     "shell.execute_reply": "2025-01-31T10:26:24.635910Z",
     "shell.execute_reply.started": "2025-01-31T10:26:24.621145Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#I would like a medium chicken with pesto sauce. What drinks do you have?\n",
    "#I would like a roasted chicken. Please add a Fanta as my drink.\n",
    "#I would like a boneless chicken. I would prefer a medium-sized drink."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "032751c18c5947a28533b5c5a5576d80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "04b24eeb1e4c46d1aa73e08dc1a57515": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06b9831997f944de96c5e76ca4c3da81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65d5e8fd7e9a45f483bbd55204b1ef0f",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9a8faff6650f40bc891fcd1a2360532c",
      "value": 2
     }
    },
    "1f6e0617d70f409bb21908d52d6a0c1a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "298529c9a4214f26ab2bd9935dd89630": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b7b981ff9054794943b066cb36ac951": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3567f0f289d045b1a8c525035975b6ff",
      "placeholder": "​",
      "style": "IPY_MODEL_598287ed5e4b430097ce2d11bb6eb721",
      "value": " 2/2 [05:52&lt;00:00, 160.33s/it]"
     }
    },
    "3567f0f289d045b1a8c525035975b6ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "496f37f6e85a489ea428fed02a491898": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "53ed7b2ba46f43bfa9ab0fde19fc819f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "598287ed5e4b430097ce2d11bb6eb721": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5dae29c158f240e3b68695d2e326ab92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3c5d334d9544af9a96f71c2d37882f6",
      "placeholder": "​",
      "style": "IPY_MODEL_032751c18c5947a28533b5c5a5576d80",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "65d5e8fd7e9a45f483bbd55204b1ef0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83ad52b5eae44264a64109a9c4e72122": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_298529c9a4214f26ab2bd9935dd89630",
      "placeholder": "​",
      "style": "IPY_MODEL_b6afe76da067454bac56d2b5b4a93729",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "882dda8de0e04421bf8c41efe0ff50d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91694bf4beac43ec8b51cab985541bc5",
      "placeholder": "​",
      "style": "IPY_MODEL_ce98c9fd13094cf7b755e1fba226a667",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "88d8d77ed5fa4a49a719716ee584de59": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cbb0d9aa9f5415ea71fa5007eb55838": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b5683cf5136b49ec982b634d4a0a2bb9",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_496f37f6e85a489ea428fed02a491898",
      "value": 4
     }
    },
    "91694bf4beac43ec8b51cab985541bc5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93003d4a25da4177b871bfbe66c23e9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_83ad52b5eae44264a64109a9c4e72122",
       "IPY_MODEL_ddc112f8799a42c8bfd8f72e712435c0",
       "IPY_MODEL_ef6f1daeebd24a1c82715a5aff77e967"
      ],
      "layout": "IPY_MODEL_88d8d77ed5fa4a49a719716ee584de59"
     }
    },
    "9a8faff6650f40bc891fcd1a2360532c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ad07bc379abc4bf2a733b0008c5356e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3c5d334d9544af9a96f71c2d37882f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5683cf5136b49ec982b634d4a0a2bb9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6afe76da067454bac56d2b5b4a93729": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be373cf06ffa440b8c2988fd5d4800d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3404f762598443da0f147f33cae755d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5dae29c158f240e3b68695d2e326ab92",
       "IPY_MODEL_06b9831997f944de96c5e76ca4c3da81",
       "IPY_MODEL_2b7b981ff9054794943b066cb36ac951"
      ],
      "layout": "IPY_MODEL_ad07bc379abc4bf2a733b0008c5356e0"
     }
    },
    "cbe05d191acd4370854a45df64b1065c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04b24eeb1e4c46d1aa73e08dc1a57515",
      "placeholder": "​",
      "style": "IPY_MODEL_cd1048c02e2e49cc88bd49f8bfe3347e",
      "value": " 4/4 [07:14&lt;00:00, 228.55s/it]"
     }
    },
    "cd1048c02e2e49cc88bd49f8bfe3347e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ce98c9fd13094cf7b755e1fba226a667": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d0bb3f0aca524832bf613ef3f1275ade": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2b18283577248749538e8ff16f65e54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d5d74bf13b5b4305beec14186a320349": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_882dda8de0e04421bf8c41efe0ff50d3",
       "IPY_MODEL_8cbb0d9aa9f5415ea71fa5007eb55838",
       "IPY_MODEL_cbe05d191acd4370854a45df64b1065c"
      ],
      "layout": "IPY_MODEL_1f6e0617d70f409bb21908d52d6a0c1a"
     }
    },
    "ddc112f8799a42c8bfd8f72e712435c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0bb3f0aca524832bf613ef3f1275ade",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_53ed7b2ba46f43bfa9ab0fde19fc819f",
      "value": 2
     }
    },
    "ef6f1daeebd24a1c82715a5aff77e967": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be373cf06ffa440b8c2988fd5d4800d7",
      "placeholder": "​",
      "style": "IPY_MODEL_d2b18283577248749538e8ff16f65e54",
      "value": " 2/2 [03:17&lt;00:00, 100.85s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
